{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDAOKexhbcFV",
        "outputId": "8ef24005-2a35-46a9-8a79-527d1da14710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'OnePixelAttackCIFAR10' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# If running in Google Colab, import files\n",
        "try:\n",
        "    import google.colab\n",
        "    in_colab = True\n",
        "except:\n",
        "    in_colab = False\n",
        "\n",
        "if in_colab:\n",
        "    !git clone https://github.com/ahojszyk/OnePixelAttackCIFAR10.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PZqzro9Jbhu1"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D, Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import json\n",
        "import os\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import time\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IvZl4BDsbsFj"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Net:\n",
        "    \"\"\"\n",
        "    A class representing various CNN architectures for CIFAR-10.\n",
        "    Includes training, evaluation, prediction, and visualization capabilities.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, epochs=200, batch_size=128, load_weights=True, net_type='LeNet'):\n",
        "\n",
        "        \"\"\"\n",
        "        Initialize the network with the specified parameters.\n",
        "\n",
        "        Args:\n",
        "            epochs (int): Number of training epochs.\n",
        "            batch_size (int): Batch size for training.\n",
        "            load_weights (bool): Whether to load pre-trained weights if available.\n",
        "            net_type (str): The type of network architecture to use.\n",
        "        \"\"\"\n",
        "\n",
        "        self.name = net_type\n",
        "        self.model_filename = f'OnePixelAttackCIFAR10/networks/models/{net_type}.keras'\n",
        "        self.checkpoint_filepath = f'OnePixelAttackCIFAR10/networks/models/{net_type}_checkpoint.keras'\n",
        "        self.num_classes = 10\n",
        "        self.input_shape = (32, 32, 3)\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.weight_decay = 0.0001\n",
        "        self.log_filepath = f'OnePixelAttackCIFAR10/networks/models/{net_type}'\n",
        "\n",
        "        if load_weights:\n",
        "            try:\n",
        "                self._model = load_model(self.model_filename)\n",
        "                print('Successfully loaded', self.name)\n",
        "            except (ImportError, ValueError, OSError):\n",
        "                print('Failed to load', self.name)\n",
        "\n",
        "    def count_params(self):\n",
        "        \"\"\"\n",
        "        Return the number of trainable parameters in the model.\n",
        "\n",
        "        Returns:\n",
        "            int: Number of trainable parameters.\n",
        "        \"\"\"\n",
        "        return self._model.count_params()\n",
        "\n",
        "    def color_preprocessing(self, x_train, x_test):\n",
        "\n",
        "        \"\"\"\n",
        "        Normalize image data for training and testing.\n",
        "\n",
        "        Args:\n",
        "            x_train (np.array): Training images.\n",
        "            x_test (np.array): Testing images.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[np.array, np.array]: Preprocessed training and testing images.\n",
        "        \"\"\"\n",
        "\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "        mean = [125.307, 122.95, 113.865]\n",
        "        std  = [62.9932, 62.0887, 66.7048]\n",
        "        for i in range(3):\n",
        "            x_train[:,:,:,i] = (x_train[:,:,:,i] - mean[i]) / std[i]\n",
        "            x_test[:,:,:,i] = (x_test[:,:,:,i] - mean[i]) / std[i]\n",
        "        return x_train, x_test\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Build the model based on the specified network type.\n",
        "\n",
        "        Returns:\n",
        "            keras.Model: Compiled model.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.name == 'LeNet':\n",
        "            model = Sequential()\n",
        "            model.add(Conv2D(6, kernel_size=5, strides=1,  activation='relu', input_shape=(32,32,3), padding='same'))\n",
        "            model.add(AveragePooling2D(pool_size=2, strides = 2))\n",
        "            model.add(Conv2D(16, kernel_size=5, strides=1, activation='relu', padding='valid'))\n",
        "            model.add(AveragePooling2D(pool_size=2, strides = 2))\n",
        "            model.add(Conv2D(120, kernel_size=5, strides=1, activation='relu', padding='valid'))\n",
        "            model.add(Flatten())\n",
        "            model.add(Dense(84, activation='relu'))\n",
        "            model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "        elif self.name == 'All Convolution':\n",
        "            model = Sequential()\n",
        "            model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', input_shape=(32,32,3)))\n",
        "            model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same'))\n",
        "            model.add(Conv2D(96, (3, 3), activation='relu', padding = 'same', strides = 2))\n",
        "            model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "            model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same'))\n",
        "\n",
        "            model.add(Dropout(0.3))\n",
        "\n",
        "            model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2))\n",
        "            model.add(Conv2D(192, (3, 3), activation='relu', padding = 'same', strides = 2))\n",
        "            model.add(Conv2D(192, (1, 1), activation='relu', padding='valid'))\n",
        "            model.add(Conv2D(10, (1, 1), activation='relu', padding='valid'))\n",
        "\n",
        "            model.add(GlobalAveragePooling2D())\n",
        "            model.add(Activation('softmax'))\n",
        "\n",
        "        elif self.name == 'VGG16':\n",
        "            model = Sequential()\n",
        "            model.add(Conv2D(64, (3, 3), padding='same',\n",
        "                         input_shape=(32,32,3),kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dropout(0.3))\n",
        "\n",
        "            model.add(Conv2D(64, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "            model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dropout(0.4))\n",
        "\n",
        "            model.add(Conv2D(128, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "            model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dropout(0.4))\n",
        "\n",
        "            model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dropout(0.4))\n",
        "\n",
        "            model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "            model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dropout(0.4))\n",
        "\n",
        "            model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dropout(0.4))\n",
        "\n",
        "            model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "            model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dropout(0.4))\n",
        "\n",
        "            model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dropout(0.4))\n",
        "\n",
        "            model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "            model.add(Dropout(0.5))\n",
        "\n",
        "            model.add(Flatten())\n",
        "            model.add(Dense(2048,kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "            model.add(Dense(2048,kernel_regularizer=l2(self.weight_decay)))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(BatchNormalization())\n",
        "\n",
        "            model.add(Dropout(0.5))\n",
        "            model.add(Dense(self.num_classes))\n",
        "            model.add(Activation('softmax'))\n",
        "\n",
        "        elif self.name == 'VGG8':\n",
        "            model = Sequential()\n",
        "            model.add(Conv2D(128,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same', input_shape = (32,32,3)))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Conv2D(128,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(MaxPooling2D((2,2)))\n",
        "            model.add(Dropout(0.2))\n",
        "            model.add(Conv2D(256,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Conv2D(256,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(MaxPooling2D((2,2)))\n",
        "            model.add(Dropout(0.3))\n",
        "            model.add(Conv2D(512,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Conv2D(512,(3,3), activation = 'relu', kernel_initializer = 'he_uniform', padding = 'same'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(MaxPooling2D((2,2)))\n",
        "            model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "            model.add(Flatten())\n",
        "            model.add(Dense(8192, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Dense(1024, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
        "            model.add(Dropout(0.5))\n",
        "            model.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "        elif self.name == \"Network in Network\":\n",
        "            model = Sequential()\n",
        "            model.add(Conv2D(192, (5, 5), padding='same', kernel_regularizer=keras.regularizers.l2(self.weight_decay), kernel_initializer=\"he_normal\", input_shape=self.input_shape))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(Conv2D(160, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(self.weight_decay), kernel_initializer=\"he_normal\"))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(Conv2D(96, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(self.weight_decay), kernel_initializer=\"he_normal\"))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(MaxPooling2D(pool_size=(3, 3),strides=(2,2),padding = 'same'))\n",
        "\n",
        "            model.add(Dropout(0.5))\n",
        "\n",
        "            model.add(Conv2D(192, (5, 5), padding='same', kernel_regularizer=keras.regularizers.l2(self.weight_decay), kernel_initializer=\"he_normal\"))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(Conv2D(192, (1, 1),padding='same', kernel_regularizer=keras.regularizers.l2(self.weight_decay), kernel_initializer=\"he_normal\"))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(Conv2D(192, (1, 1),padding='same', kernel_regularizer=keras.regularizers.l2(self.weight_decay), kernel_initializer=\"he_normal\"))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(MaxPooling2D(pool_size=(3, 3),strides=(2,2),padding = 'same'))\n",
        "\n",
        "            model.add(Dropout(0.5))\n",
        "\n",
        "            model.add(Conv2D(192, (3, 3), padding='same', kernel_regularizer=keras.regularizers.l2(self.weight_decay), kernel_initializer=\"he_normal\"))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(Conv2D(192, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(self.weight_decay), kernel_initializer=\"he_normal\"))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(Conv2D(10, (1, 1), padding='same', kernel_regularizer=keras.regularizers.l2(self.weight_decay), kernel_initializer=\"he_normal\"))\n",
        "            model.add(BatchNormalization())\n",
        "            model.add(Activation('relu'))\n",
        "\n",
        "            model.add(GlobalAveragePooling2D())\n",
        "            model.add(Activation('softmax'))\n",
        "\n",
        "        model.compile(optimizer=Adam(learning_rate=self.weight_decay),loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def train(self, data_aug=True, early_stopping=True, patience=15):\n",
        "\n",
        "        \"\"\"\n",
        "        Train the model on the CIFAR-10 dataset.\n",
        "\n",
        "        Args:\n",
        "            data_aug (bool): Whether to use data augmentation.\n",
        "            early_stopping (bool): Whether to use early stopping.\n",
        "            patience (int): Number of epochs to wait for early stopping.\n",
        "        \"\"\"\n",
        "\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        y_train = tf.keras.utils.to_categorical(y_train, self.num_classes)\n",
        "        y_test = tf.keras.utils.to_categorical(y_test, self.num_classes)\n",
        "\n",
        "        # Color preprocessing\n",
        "        x_train, x_test = self.color_preprocessing(x_train, x_test)\n",
        "\n",
        "        # Build network\n",
        "        model = self.build_model()\n",
        "        model.summary()\n",
        "\n",
        "        print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
        "\n",
        "        # EarlyStopping callback\n",
        "        callbacks = []\n",
        "        if early_stopping:\n",
        "            early_stop = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
        "            callbacks.append(early_stop)\n",
        "\n",
        "        # ModelCheckpoint callback\n",
        "        checkpoint_callback = ModelCheckpoint(\n",
        "            self.checkpoint_filepath,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            mode='min',\n",
        "            verbose=1\n",
        "        )\n",
        "        callbacks.append(checkpoint_callback)\n",
        "\n",
        "        # Start timing the training process\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Using real-time data augmentation\n",
        "        if data_aug:\n",
        "            print('Using real-time data augmentation.')\n",
        "            datagen = ImageDataGenerator(horizontal_flip=True,\n",
        "                                          width_shift_range=0.125,\n",
        "                                          height_shift_range=0.125,\n",
        "                                          fill_mode='constant',\n",
        "                                          cval=0.)\n",
        "            datagen.fit(x_train)\n",
        "\n",
        "            hist = model.fit(datagen.flow(x_train, y_train, batch_size=self.batch_size),\n",
        "                             epochs=self.epochs,\n",
        "                             validation_data=(x_test, y_test),\n",
        "                             callbacks=callbacks)\n",
        "        else:\n",
        "            print('No data augmentation.')\n",
        "            hist = model.fit(x_train, y_train, batch_size=self.batch_size,\n",
        "                             epochs=self.epochs,\n",
        "                             validation_data=(x_test, y_test),\n",
        "                             callbacks=callbacks)\n",
        "\n",
        "        # End timing\n",
        "        self.training_time = time.time() - start_time\n",
        "\n",
        "        print(\"Time:  \", self.training_time)\n",
        "\n",
        "        # Save the training history\n",
        "        with open(self.log_filepath + 'training_history.json', 'w') as f:\n",
        "            json.dump(hist.history, f)\n",
        "\n",
        "        # Save the final model\n",
        "        model.save(self.model_filename)\n",
        "        self._model = model\n",
        "\n",
        "    def plot_history(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Plot training and validation loss and accuracy from training history.\n",
        "        \"\"\"\n",
        "\n",
        "        # Load the history\n",
        "        with open(self.log_filepath + 'training_history.json', 'r') as f:\n",
        "            history = json.load(f)\n",
        "\n",
        "        # Get the number of epochs\n",
        "        epochs = range(1, len(history['loss']) + 1)\n",
        "\n",
        "        # Plot training & validation loss values\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        # Loss Plot\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(epochs, history['loss'], '-', label='Training Loss', color = 'blue')\n",
        "        plt.plot(epochs, history['val_loss'], '-', label='Validation Loss', color = 'red')\n",
        "        plt.title('Training and Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        # Accuracy Plot\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, history['accuracy'], '-', label='Training Accuracy', color = 'blue')\n",
        "        plt.plot(epochs, history['val_accuracy'], '-', label='Validation Accuracy', color = 'red')\n",
        "        plt.title('Training and Validation Accuracy')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.suptitle(self.name)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def color_process(self, imgs):\n",
        "\n",
        "      \"\"\"\n",
        "      Normalize the input images using the given mean and standard deviation.\n",
        "      \"\"\"\n",
        "\n",
        "      if imgs.ndim < 4:\n",
        "          imgs = np.array([imgs])\n",
        "      imgs = imgs.astype('float32')\n",
        "      mean = [125.307, 122.95, 113.865]\n",
        "      std  = [62.9932, 62.0887, 66.7048]\n",
        "      for img in imgs:\n",
        "          for i in range(3):\n",
        "              img[:, :, i] = (img[:, :, i] - mean[i]) / std[i]\n",
        "      return imgs\n",
        "\n",
        "    def predict(self, img):\n",
        "\n",
        "        \"\"\"\n",
        "        Process the image and predict the labels in batch mode.\n",
        "        \"\"\"\n",
        "\n",
        "        processed = self.color_process(img)\n",
        "        return self._model.predict(processed, batch_size=self.batch_size, verbose=0)\n",
        "\n",
        "    def predict_one(self, img):\n",
        "        \"\"\"\n",
        "        Predict the label for a single image.\n",
        "        \"\"\"\n",
        "        return self.predict(img)[0]\n",
        "\n",
        "    def accuracy(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Evaluate the model accuracy on the CIFAR-10 test dataset.\n",
        "        \"\"\"\n",
        "\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        y_train = tf.keras.utils.to_categorical(y_train, self.num_classes)\n",
        "        y_test = tf.keras.utils.to_categorical(y_test, self.num_classes)\n",
        "\n",
        "        # color preprocessing\n",
        "        x_train, x_test = self.color_preprocessing(x_train, x_test)\n",
        "\n",
        "        return self._model.evaluate(x_test, y_test, verbose=0)[1]\n",
        "\n",
        "    def visualize_confusion_matrix(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Generate and visualize the confusion matrix for the model predictions on test data.\n",
        "        \"\"\"\n",
        "\n",
        "        # Load test data\n",
        "        _, (x_test, y_test) = cifar10.load_data()\n",
        "        y_test = tf.keras.utils.to_categorical(y_test, self.num_classes)\n",
        "\n",
        "        # Preprocess test data\n",
        "        x_test, _ = self.color_preprocessing(x_test, x_test)\n",
        "\n",
        "        # Get predictions\n",
        "        y_pred = self._model.predict(x_test, batch_size=self.batch_size)\n",
        "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "        y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
        "                    xticklabels=range(self.num_classes),\n",
        "                    yticklabels=range(self.num_classes))\n",
        "        plt.xlabel(\"Predicted Label\")\n",
        "        plt.ylabel(\"True Label\")\n",
        "        plt.title(f\"{self.name} Confusion Matrix\")\n",
        "        plt.show()\n",
        "\n",
        "    def visualize_predictions(self, num_samples=10):\n",
        "\n",
        "        \"\"\"\n",
        "        Visualize sample predictions alongside their true class labels.\n",
        "\n",
        "        Parameters:\n",
        "        - num_samples: Number of samples to visualize (default is 10).\n",
        "        \"\"\"\n",
        "\n",
        "        # Class names for CIFAR-10 dataset\n",
        "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                       'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "        # Load the test data\n",
        "        _, (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "        # Flatten the true labels for easy indexing\n",
        "        y_true = y_test.flatten()\n",
        "\n",
        "        # Randomly select samples to display\n",
        "        indices = np.random.choice(range(len(x_test)), size=num_samples, replace=False)\n",
        "\n",
        "        # Adjust layout for better spacing\n",
        "        fig, axs = plt.subplots(2, 5, figsize=(15, 7))\n",
        "        plt.subplots_adjust(wspace=0.5, hspace=0.5)  # Add space between plots\n",
        "\n",
        "        for i, idx in enumerate(indices):\n",
        "            # Get the unprocessed image\n",
        "            img = x_test[idx]\n",
        "\n",
        "            # Use predict_one to get the prediction for the image\n",
        "            pred_label = np.argmax(self.predict_one(img))\n",
        "\n",
        "            # Convert numeric labels to class names\n",
        "            true_class_name = class_names[y_true[idx]]\n",
        "            pred_class_name = class_names[pred_label]\n",
        "\n",
        "            # Plot the unprocessed image\n",
        "            ax = axs[i // 5, i % 5]\n",
        "            ax.imshow(img.astype(\"uint8\"))\n",
        "            ax.set_title(f\"True: {true_class_name}\\nPred: {pred_class_name}\",\n",
        "                         color=(\"green\" if true_class_name == pred_class_name else \"red\"))\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "        plt.suptitle(\"Sample Predictions with True and Predicted Class Names\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "9K2yfrrXb1V9",
        "outputId": "4c7cdef4-5c9c-493d-f03a-ec9d6135cacb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded All Convolution\n",
            "Successfully loaded Network in Network\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           model_name  accuracy  parameter_count\n",
              "0     All Convolution    0.8734          1369738\n",
              "1  Network in Network    0.8708           972658"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cab5206-e5c0-4b0d-997c-3a1d41b9e33a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>parameter_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>All Convolution</td>\n",
              "      <td>0.8734</td>\n",
              "      <td>1369738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Network in Network</td>\n",
              "      <td>0.8708</td>\n",
              "      <td>972658</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cab5206-e5c0-4b0d-997c-3a1d41b9e33a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4cab5206-e5c0-4b0d-997c-3a1d41b9e33a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4cab5206-e5c0-4b0d-997c-3a1d41b9e33a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff078e42-0905-4e13-b0b7-731164776639\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff078e42-0905-4e13-b0b7-731164776639')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff078e42-0905-4e13-b0b7-731164776639 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_eeb1bdbe-bbfd-46ef-96d4-1dfcc8ec879a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('network_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eeb1bdbe-bbfd-46ef-96d4-1dfcc8ec879a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('network_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "network_stats",
              "summary": "{\n  \"name\": \"network_stats\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Network in Network\",\n          \"All Convolution\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0018384776310849781,\n        \"min\": 0.8708,\n        \"max\": 0.8734,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8708,\n          0.8734\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"parameter_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 280777,\n        \"min\": 972658,\n        \"max\": 1369738,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          972658,\n          1369738\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Load pretrained models\n",
        "AllConv = Net(load_weights=True, net_type='All Convolution')\n",
        "VGG16 = Net(load_weights=True, net_type='VGG16')\n",
        "NiN = Net(load_weights=True, net_type='Network in Network')\n",
        "\n",
        "models = [AllConv, NiN, VGG16]\n",
        "\n",
        "def assess_models(models_list):\n",
        "    \"\"\"\n",
        "    Evaluates the performance of a list of models on the CIFAR10 dataset and returns results as DataFrames.\n",
        "\n",
        "    Parameters:\n",
        "        models_list (list): A list of model objects. Each model should have:\n",
        "                            - `name` (str): The model's name.\n",
        "                            - `predict(data)` method: Returns predictions for the input data.\n",
        "                            - `count_params()` method: Returns the total number of parameters in the model.\n",
        "                            - `training_time` attribute: The time taken to train the model.\n",
        "\n",
        "    Returns:\n",
        "        tuple:\n",
        "            - model_performance_df (pd.DataFrame): A DataFrame with columns\n",
        "                                                  ['model_name', 'accuracy', 'parameter_count', 'training_time']\n",
        "            - correctly_classified_images_df (pd.DataFrame): A DataFrame with columns\n",
        "                                                            ['model_name', 'image_index', 'true_label', 'confidence', 'predictions']\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize lists to store results\n",
        "    correctly_classified_images = []\n",
        "    model_performance = []\n",
        "\n",
        "    # Load Fashion MNIST dataset\n",
        "    (train_data, train_labels), (test_data, test_labels) = cifar10.load_data()\n",
        "\n",
        "    # Iterate through each model in the list\n",
        "    for model in models_list:\n",
        "        # Train the model (if needed)\n",
        "        if not hasattr(model, '_model') or model._model is None:\n",
        "           model.train()\n",
        "\n",
        "        # Get predictions for the test dataset\n",
        "        predictions = model.predict(test_data)\n",
        "\n",
        "        # Identify correctly classified images\n",
        "        correctly_classified = [\n",
        "            [model.name, img_idx, true_label[0], np.max(pred), pred]\n",
        "            for img_idx, (true_label, pred) in enumerate(zip(test_labels, predictions))\n",
        "            if true_label == np.argmax(pred)]\n",
        "\n",
        "        # Calculate accuracy as the ratio of correctly classified images to total images\n",
        "        accuracy = len(correctly_classified) / len(test_data)\n",
        "\n",
        "        # Add correctly classified image details and model performance stats\n",
        "        correctly_classified_images += correctly_classified\n",
        "        model_performance.append([model.name, accuracy, model.count_params() , model.training_time])\n",
        "\n",
        "    # Convert lists to DataFrames\n",
        "    correctly_classified_images_df = pd.DataFrame(\n",
        "        correctly_classified_images,\n",
        "        columns=['model_name', 'image_index', 'true_label', 'confidence', 'predictions']\n",
        "    )\n",
        "    model_performance_df = pd.DataFrame(\n",
        "        model_performance,\n",
        "        columns=['model_name', 'accuracy', 'parameter_count' , 'training_time']\n",
        "    )\n",
        "\n",
        "    # Return DataFrames\n",
        "    return model_performance_df, correctly_classified_images_df\n",
        "\n",
        "\n",
        "network_stats, correct_imgs = assess_models(models)\n",
        "\n",
        "\n",
        "network_stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from OnePixelAttackCIFAR10.DifferentialEvolution import differential_evolution\n",
        "\n",
        "\n",
        "class Attack:\n",
        "    def __init__(self, x_test, y_test, models, csv_path, correct_imgs, maxiter=75, popsize=400, verbose=False):\n",
        "        \"\"\"\n",
        "        Initializes the Attack class with data, models, and parameters.\n",
        "\n",
        "        Parameters:\n",
        "        x_test (numpy.ndarray): The test dataset images to be used in the attack.\n",
        "        y_test (numpy.ndarray): The test dataset labels corresponding to the images.\n",
        "        models (list): A list of model objects to be attacked.\n",
        "        csv_path (str): The path to the results CSV file where attack results will be saved.\n",
        "        correct_imgs (pd.DataFrame): A DataFrame containing the images that were correctly classified by the models.\n",
        "        maxiter (int): The maximum number of iterations for the differential evolution algorithm.\n",
        "        popsize (int): The population size used in the differential evolution algorithm.\n",
        "        verbose (bool): Flag to enable or disable verbose logging during the attack process.\n",
        "        \"\"\"\n",
        "        self.x_test = x_test\n",
        "        self.y_test = y_test\n",
        "        self.models = models\n",
        "        self.csv_path = csv_path\n",
        "        self.correct_imgs = correct_imgs\n",
        "        self.maxiter = maxiter\n",
        "        self.popsize = popsize\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # Ensure the results CSV exists or create an empty DataFrame\n",
        "        if os.path.exists(csv_path):\n",
        "            # Load the DataFrame and ensure headers are present\n",
        "            self.results_df = pd.read_csv(csv_path)\n",
        "            expected_columns = [\n",
        "                'model_name', 'pixel_count', 'img_id', 'actual_class',\n",
        "                'predicted_class', 'success', 'confidence_diff',\n",
        "                'prior_probs', 'predicted_probs', 'perturbation', 'target_class'\n",
        "            ]\n",
        "            if list(self.results_df.columns) != expected_columns:\n",
        "                print(f\"CSV file at {csv_path} is missing headers. Adding the expected headers.\")\n",
        "                self.results_df.columns = expected_columns  # Assign expected headers to the DataFrame\n",
        "\n",
        "                # Save the DataFrame back to the CSV with the correct headers\n",
        "                self.results_df.to_csv(csv_path, index=False)\n",
        "        else:\n",
        "            # Create a new DataFrame with the required columns\n",
        "            columns = [\n",
        "                'model_name', 'pixel_count', 'img_id', 'actual_class',\n",
        "                'predicted_class', 'success', 'confidence_diff',\n",
        "                'prior_probs', 'predicted_probs', 'perturbation', 'target_class'\n",
        "            ]\n",
        "            self.results_df = pd.DataFrame(columns=columns)\n",
        "\n",
        "        # Track completed image-model-pixel combinations\n",
        "        self.completed_combinations = set(zip(\n",
        "            self.results_df['model_name'],\n",
        "            self.results_df['pixel_count'],\n",
        "            self.results_df['img_id']\n",
        "        ))\n",
        "\n",
        "    def _get_sampled_images(self, samples):\n",
        "        \"\"\"\n",
        "        Samples 10% of images per class to ensure a balanced dataset.\n",
        "\n",
        "        Parameters:\n",
        "            samples (int): Total number of images to sample from the dataset.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Array of sampled image indices.\n",
        "        \"\"\"\n",
        "        # Get the list of fully correct images (images correctly classified by all models)\n",
        "        total_models = self.correct_imgs['model_name'].nunique()\n",
        "        fully_correct_imgs = self.correct_imgs.groupby('image_index').filter(\n",
        "            lambda x: x['model_name'].nunique() == total_models\n",
        "        )\n",
        "\n",
        "        # Exclude already used images\n",
        "        existing_imgs = self.results_df['img_id'].unique() if not self.results_df.empty else []\n",
        "        eligible_images = fully_correct_imgs[~fully_correct_imgs['image_index'].isin(existing_imgs)]\n",
        "\n",
        "        # Ensure there are enough images left to sample from\n",
        "        if len(eligible_images) < samples:\n",
        "            raise ValueError(f\"Not enough unique images remaining. Needed: {samples}, Available: {len(eligible_images)}\")\n",
        "\n",
        "        # Perform balanced sampling across classes\n",
        "        sampled_images = eligible_images.groupby('true_label').apply(lambda x: x.sample(int(samples / 10), replace=False))\n",
        "        return sampled_images['image_index'].unique()\n",
        "\n",
        "    @staticmethod\n",
        "    def perturb_image(xs, img):\n",
        "        \"\"\"\n",
        "        Perturbs an image using the given pixel perturbations.\n",
        "\n",
        "        Parameters:\n",
        "            xs (numpy.ndarray): Array of perturbations to apply to the image.\n",
        "            img (numpy.ndarray): The original image to perturb.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Array of perturbed images after applying the perturbations.\n",
        "        \"\"\"\n",
        "        if xs.ndim < 2:\n",
        "            xs = np.array([xs])\n",
        "\n",
        "        tile = [len(xs)] + [1]*(xs.ndim+1)\n",
        "        imgs = np.tile(img, tile)\n",
        "        xs = xs.astype(int)\n",
        "\n",
        "        for x,img in zip(xs, imgs):\n",
        "          pixels = np.split(x, len(x) // 5)\n",
        "          for pixel in pixels:\n",
        "              x_pos, y_pos, *rgb = pixel\n",
        "              img[x_pos, y_pos] = rgb\n",
        "\n",
        "        return imgs\n",
        "\n",
        "\n",
        "    def predict_classes(self, xs, img, target_class, model, minimize=True):\n",
        "        \"\"\"\n",
        "        Predicts the class probabilities of perturbed images.\n",
        "\n",
        "        Parameters:\n",
        "            xs (numpy.ndarray): Array of perturbations to apply to the image.\n",
        "            img (numpy.ndarray): The original image to perturb.\n",
        "            target_class (int): The target class for the attack.\n",
        "            model (object): The model used to evaluate the perturbed image.\n",
        "            minimize (bool): Whether to minimize or maximize the objective (target class).\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: Predicted probabilities for the target class after perturbing the image.\n",
        "        \"\"\"\n",
        "        imgs_perturbed = self.perturb_image(xs, img)\n",
        "        predictions = model.predict(imgs_perturbed)[:, target_class]\n",
        "        return predictions if minimize else 1 - predictions\n",
        "\n",
        "    def attack_success(self, x, img, target_class, model, targeted_attack):\n",
        "        \"\"\"\n",
        "        Checks if the attack is successful.\n",
        "\n",
        "        Parameters:\n",
        "            x (numpy.ndarray): Perturbation vector applied to the image.\n",
        "            img (numpy.ndarray): The original image.\n",
        "            target_class (int): The target class for the attack.\n",
        "            model (object): The model used to evaluate the perturbed image.\n",
        "            targeted_attack (bool): Whether this is a targeted attack.\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the attack successfully manipulates the model’s prediction, False otherwise.\n",
        "        \"\"\"\n",
        "\n",
        "        attack_image = self.perturb_image(x, img)\n",
        "        confidence = model.predict(attack_image)[0]\n",
        "        predicted_class = np.argmax(confidence)\n",
        "\n",
        "        if ((targeted_attack and predicted_class == target_class) or\n",
        "            (not targeted_attack and predicted_class != target_class)):\n",
        "            return True\n",
        "        #return False\n",
        "\n",
        "    def attack(self, img_id, model, target=None, pixel_count=1):\n",
        "        \"\"\"\n",
        "        Executes a one-pixel attack on a single image.\n",
        "\n",
        "        Parameters:\n",
        "            img_id (int): ID of the image to attack.\n",
        "            model (object): The model used for the attack.\n",
        "            target (int): Target class for the attack (used in targeted attacks).\n",
        "            pixel_count (int): Number of pixels to perturb in the image.\n",
        "\n",
        "        Returns:\n",
        "            dict: Attack results including metadata and model predictions after the attack.\n",
        "        \"\"\"\n",
        "        targeted_attack = target is not None\n",
        "        target_class = target if targeted_attack else self.y_test[img_id, 0]\n",
        "        bounds = [(0,32), (0,32), (0,256), (0,256), (0,256)] * pixel_count\n",
        "        popmul = max(1, self.popsize // len(bounds))\n",
        "\n",
        "        def predict_fn(xs):\n",
        "            return self.predict_classes(xs, self.x_test[img_id], target_class, model, target is None)\n",
        "\n",
        "        def callback_fn(x, convergence):\n",
        "            return self.attack_success(x, self.x_test[img_id], target_class, model, targeted_attack)\n",
        "\n",
        "        attack_result = differential_evolution(\n",
        "            predict_fn, bounds, maxiter=self.maxiter, popsize=popmul,\n",
        "            recombination=1, atol=-1, callback=callback_fn, polish=False)\n",
        "\n",
        "        attack_image = self.perturb_image(attack_result.x, self.x_test[img_id])[0]\n",
        "        prior_probs = model.predict_one(self.x_test[img_id])\n",
        "        predicted_probs = model.predict_one(attack_image)\n",
        "        predicted_class = np.argmax(predicted_probs)\n",
        "        actual_class = self.y_test[img_id,0]\n",
        "        success = predicted_class != actual_class\n",
        "        cdiff = prior_probs[actual_class] - predicted_probs[actual_class]\n",
        "\n",
        "        if self.verbose:\n",
        "            plt.imshow(attack_image)\n",
        "            plt.show()\n",
        "            print(f\"Actual: {actual_class}, Predicted: {predicted_class}\")\n",
        "\n",
        "        # Add target_class to the returned result\n",
        "        return [\n",
        "            model.name, pixel_count, img_id, actual_class, predicted_class,\n",
        "            success, cdiff, prior_probs, predicted_probs, attack_result.x, target_class\n",
        "        ]\n",
        "\n",
        "\n",
        "    def attack_all(self, samples=100, pixels=(1, 2, 3, 4, 5, 6), targeted=False):\n",
        "        \"\"\"\n",
        "        Executes one-pixel attacks on multiple images and saves results.\n",
        "\n",
        "        Parameters:\n",
        "            samples (int): Number of images to sample for the attack.\n",
        "            pixels (tuple): Tuple of pixel counts to use for the attacks.\n",
        "            targeted (bool): Flag indicating whether to perform targeted attacks.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame containing the results of the attacks, including predictions and metadata.\n",
        "        \"\"\"\n",
        "        sampled_images = self._get_sampled_images(samples)\n",
        "\n",
        "        for model in self.models:\n",
        "            for pixel_count in pixels:\n",
        "                for img_id in sampled_images:\n",
        "                    if (model.name, pixel_count, img_id) in self.completed_combinations:\n",
        "                        continue\n",
        "\n",
        "                    print(f'\\n{model.name} - image {img_id} - pixel count {pixel_count}')\n",
        "                    targets = [None] if not targeted else range(10)\n",
        "\n",
        "                    for target in targets:\n",
        "                        if targeted and target == self.y_test[img_id,0]:\n",
        "                            continue\n",
        "\n",
        "                        result = self.attack(img_id, model, target, pixel_count)\n",
        "                        result_df = pd.DataFrame([result], columns=self.results_df.columns)\n",
        "                        result_df.to_csv(self.csv_path, mode='a', header=False, index=False)\n",
        "                        self.completed_combinations.add((model.name, pixel_count, img_id))\n",
        "\n",
        "        final_results_df = pd.read_csv(self.csv_path)\n",
        "        return final_results_df"
      ],
      "metadata": {
        "id": "SpFNsMGRlS5I"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 data set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Results CSV path\n",
        "csv_path = \"resultsCIFAR10.csv\"\n",
        "\n",
        "# Create an instance of the Attack class\n",
        "attack_instance = Attack(\n",
        "    x_test=x_test,\n",
        "    y_test=y_test,\n",
        "    models=models,\n",
        "    csv_path=csv_path,\n",
        "    correct_imgs=correct_imgs,\n",
        "    maxiter=75,\n",
        "    popsize=400,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "final_results = attack_instance.attack_all(\n",
        "    samples=10,\n",
        "    pixels=(4,5),\n",
        "    targeted=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "id": "snJ7x69JpttN",
        "outputId": "f93da083-54a9-4490-93b3-8524c0836d50"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-96ee96db2f77>:84: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sampled_images = eligible_images.groupby('true_label').apply(lambda x: x.sample(int(samples / 10), replace=False))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All Convolution - image 9987 - pixel count 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual: 0, Predicted: 8\n",
            "\n",
            "All Convolution - image 4206 - pixel count 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/OnePixelAttackCIFAR10/DifferentialEvolution.py:585: RuntimeWarning: divide by zero encountered in scalar divide\n",
            "  convergence=self.tol / convergence) is True):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2016cdb1c6c4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m final_results = attack_instance.attack_all(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-96ee96db2f77>\u001b[0m in \u001b[0;36mattack_all\u001b[0;34m(self, samples, pixels, targeted)\u001b[0m\n\u001b[1;32m    230\u001b[0m                             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpixel_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                         \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                         \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-96ee96db2f77>\u001b[0m in \u001b[0;36mattack\u001b[0;34m(self, img_id, model, target, pixel_count)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_success\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargeted_attack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         attack_result = differential_evolution(\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0mpredict_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpopmul\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             recombination=1, atol=-1, callback=callback_fn, polish=False)\n",
            "\u001b[0;32m/content/OnePixelAttackCIFAR10/DifferentialEvolution.py\u001b[0m in \u001b[0;36mdifferential_evolution\u001b[0;34m(func, bounds, args, strategy, maxiter, popsize, tol, mutation, recombination, seed, callback, disp, polish, init, atol)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                          \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                                          disp=disp, init=init, atol=atol)\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/OnePixelAttackCIFAR10/DifferentialEvolution.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0;31m# evolve the population by a generation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0mwarning_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/OnePixelAttackCIFAR10/DifferentialEvolution.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_constraint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0menergies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mitersize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-96ee96db2f77>\u001b[0m in \u001b[0;36mpredict_fn\u001b[0;34m(xs)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mpredict_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcallback_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvergence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-96ee96db2f77>\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, xs, img, target_class, model, minimize)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \"\"\"\n\u001b[1;32m    129\u001b[0m         \u001b[0mimgs_perturbed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturb_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs_perturbed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mminimize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-dccd838a904c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend_to_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                     \u001b[0msingle_step_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__len__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;31m# to communicate that there is no more data to iterate over.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSYNC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 776\u001b[0;31m       ret = gen_dataset_ops.iterator_get_next(\n\u001b[0m\u001b[1;32m    777\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3079\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3080\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3081\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3082\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"IteratorGetNext\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3083\u001b[0m         \"output_shapes\", output_shapes)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}